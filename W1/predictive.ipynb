{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66911976",
   "metadata": {},
   "source": [
    "# PREDICTIVE ANALYTICS: \"WHAT WILL HAPPEN?\"\n",
    "## E-commerce Customer Analytics - Part 3 of 4\n",
    "\n",
    "OBJECTIVE: Build predictive models to forecast future outcomes\n",
    "- Customer churn prediction\n",
    "- Sales forecasting\n",
    "- Customer lifetime value prediction\n",
    "- Product demand forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0a92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7cf90",
   "metadata": {},
   "source": [
    "### 1. DATA LOADING & FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9407b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š STEP 1: Data Loading & Feature Engineering\n",
      "---------------------------------------------\n",
      "âœ… Loaded data successfully\n",
      "\n",
      "ðŸ”§ Engineering Customer Features...\n",
      "âœ… Created 26 features for 5000 customers\n",
      "Columns after merge: ['customer_id', 'first_name', 'last_name', 'email', 'age', 'gender', 'city', 'state', 'registration_date', 'customer_segment', 'is_churned', 'total_spent', 'avg_order_value', 'order_value_std', 'transaction_count', 'total_quantity', 'avg_quantity', 'avg_discount', 'first_purchase', 'last_purchase', 'days_active', 'days_since_last', 'purchase_frequency', 'support_tickets', 'avg_resolution_time', 'high_priority_tickets']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š STEP 1: Data Loading & Feature Engineering\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv('dataset/customers.csv')\n",
    "products = pd.read_csv('dataset/products.csv')\n",
    "transactions = pd.read_csv('dataset/transactions.csv')\n",
    "tickets = pd.read_csv('dataset/support_tickets.csv')\n",
    "\n",
    "# Convert date columns\n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'])\n",
    "customers['registration_date'] = pd.to_datetime(customers['registration_date'])\n",
    "\n",
    "print(f\"âœ… Loaded data successfully\")\n",
    "\n",
    "# Feature engineering for customers\n",
    "print(\"\\nðŸ”§ Engineering Customer Features...\")\n",
    "\n",
    "# Customer transaction features\n",
    "customer_features = transactions.groupby('customer_id').agg({\n",
    "    'total_amount': ['sum', 'mean', 'std', 'count'],\n",
    "    'quantity': ['sum', 'mean'],\n",
    "    'discount': 'mean',\n",
    "    'transaction_date': ['min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "customer_features.columns = ['total_spent', 'avg_order_value', 'order_value_std', 'transaction_count',\n",
    "                           'total_quantity', 'avg_quantity', 'avg_discount', 'first_purchase', 'last_purchase']\n",
    "\n",
    "# Calculate additional features\n",
    "customer_features['days_active'] = (customer_features['last_purchase'] - customer_features['first_purchase']).dt.days\n",
    "customer_features['days_since_last'] = (datetime.now() - customer_features['last_purchase']).dt.days\n",
    "customer_features['purchase_frequency'] = customer_features['transaction_count'] / (customer_features['days_active'] + 1)\n",
    "customer_features['order_value_std'] = customer_features['order_value_std'].fillna(0)\n",
    "\n",
    "# Customer support features\n",
    "support_features = tickets.groupby('customer_id').agg({\n",
    "    'ticket_id': 'count',\n",
    "    'resolution_time_hours': 'mean',\n",
    "    'priority': lambda x: (x.isin(['High', 'Critical'])).sum()\n",
    "}).round(2)\n",
    "\n",
    "support_features.columns = ['support_tickets', 'avg_resolution_time', 'high_priority_tickets']\n",
    "\n",
    "# Rebuild customers_ml step-by-step\n",
    "customers_ml = customers[['customer_id', 'first_name', 'last_name', 'email', 'age', 'gender', 'city', 'state', 'registration_date', 'customer_segment', 'is_churned']].copy()\n",
    "\n",
    "customers_ml = customers_ml.merge(customer_features, on='customer_id', how='left')\n",
    "customers_ml = customers_ml.merge(support_features, on='customer_id', how='left')\n",
    "\n",
    "# Fill missing values\n",
    "customers_ml = customers_ml.fillna(0)\n",
    "\n",
    "print(f\"âœ… Created {len(customers_ml.columns)} features for {len(customers_ml)} customers\")\n",
    "print(f\"Columns after merge: {customers_ml.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49866ddc",
   "metadata": {},
   "source": [
    "### 2. CHURN PREDICTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5e50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸŽ¯ STEP 2: Customer Churn Prediction Model (Skipped)\n",
      "---------------------------------------------\n",
      "ðŸ“Š Training Set: 4000 customers\n",
      "ðŸ“Š Test Set: 1000 customers\n",
      "ðŸ“Š Churn Rate in Training: 29.8%\n",
      "\n",
      "ðŸ¤– Training Churn Prediction Models...\n",
      "\n",
      "ðŸ“ˆ Churn Prediction Results:\n",
      "Random Forest Accuracy: 0.702\n",
      "Logistic Regression Accuracy: 0.703\n",
      "\n",
      "ðŸ” Top 5 Churn Prediction Features:\n",
      "              feature  importance\n",
      "4  purchase_frequency       0.153\n",
      "2     avg_order_value       0.142\n",
      "1         total_spent       0.140\n",
      "6     days_since_last       0.137\n",
      "0                 age       0.113\n",
      "\n",
      "âš ï¸  High Risk Customers (>70% churn probability):\n",
      "   Count: 9\n",
      "   Avg Churn Probability: 74.6%\n",
      "   Total Value at Risk: $5,126.54\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nðŸŽ¯ STEP 2: Customer Churn Prediction Model (Skipped)\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Prepare features for churn prediction\n",
    "churn_features = ['age', 'total_spent', 'avg_order_value', 'transaction_count', \n",
    "                 'purchase_frequency', 'avg_discount', 'days_since_last',\n",
    "                 'support_tickets', 'avg_resolution_time', 'high_priority_tickets']\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "customers_ml['gender_encoded'] = le.fit_transform(customers_ml['gender'])\n",
    "customers_ml['segment_encoded'] = le.fit_transform(customers_ml['customer_segment'])\n",
    "\n",
    "churn_features.extend(['gender_encoded', 'segment_encoded'])\n",
    "\n",
    "# Prepare data\n",
    "X_churn = customers_ml[churn_features].fillna(0)\n",
    "y_churn = customers_ml['is_churned']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_churn, y_churn, test_size=0.2, random_state=42, stratify=y_churn)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"ðŸ“Š Training Set: {len(X_train)} customers\")\n",
    "print(f\"ðŸ“Š Test Set: {len(X_test)} customers\")\n",
    "print(f\"ðŸ“Š Churn Rate in Training: {y_train.mean()*100:.1f}%\")\n",
    "\n",
    "# Train models\n",
    "print(\"\\nðŸ¤– Training Churn Prediction Models...\")\n",
    "\n",
    "# Random Forest Model\n",
    "rf_churn = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_churn.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression Model\n",
    "lr_churn = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_churn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_churn.predict(X_test)\n",
    "lr_pred = lr_churn.predict(X_test)\n",
    "\n",
    "rf_proba = rf_churn.predict_proba(X_test)[:, 1]\n",
    "lr_proba = lr_churn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate models\n",
    "print(f\"\\nðŸ“ˆ Churn Prediction Results:\")\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_pred):.3f}\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, lr_pred):.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': churn_features,\n",
    "    'importance': rf_churn.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nðŸ” Top 5 Churn Prediction Features:\")\n",
    "print(feature_importance.head().round(3))\n",
    "\n",
    "# Identify high-risk customers\n",
    "customers_ml['churn_probability'] = rf_churn.predict_proba(X_churn)[:, 1]\n",
    "high_risk_customers = customers_ml[customers_ml['churn_probability'] > 0.7].copy()\n",
    "\n",
    "print(f\"\\nâš ï¸  High Risk Customers (>70% churn probability):\")\n",
    "print(f\"   Count: {len(high_risk_customers)}\")\n",
    "print(f\"   Avg Churn Probability: {high_risk_customers['churn_probability'].mean():.1%}\")\n",
    "print(f\"   Total Value at Risk: ${high_risk_customers['total_spent'].sum():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cd08eb",
   "metadata": {},
   "source": [
    "### 3. CUSTOMER LIFETIME VALUE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea46d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸ’° STEP 3: Customer Lifetime Value Prediction\n",
      "---------------------------------------------\n",
      "ðŸ“Š CLV Training Set: 2810 customers\n",
      "\n",
      "ðŸ¤– Training CLV Prediction Models...\n",
      "\n",
      "ðŸ“ˆ CLV Prediction Results:\n",
      "Random Forest RÂ² Score: 0.986, RMSE: $26.26\n",
      "Linear Regression RÂ² Score: 0.930, RMSE: $59.40\n",
      "\n",
      "ðŸ’Ž CLV Segmentation:\n",
      "             Customer Count  Predicted CLV  Current Spent\n",
      "clv_segment                                              \n",
      "Low                     879         208.92         208.43\n",
      "Medium                  878         356.76         356.33\n",
      "High                    878         495.99         497.00\n",
      "Premium                 878         764.26         766.94\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nðŸ’° STEP 3: Customer Lifetime Value Prediction\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Calculate current CLV for active customers\n",
    "active_customers = customers_ml[customers_ml['is_churned'] == 0].copy()\n",
    "\n",
    "# Features for CLV prediction\n",
    "clv_features = ['age', 'transaction_count', 'avg_order_value', 'purchase_frequency',\n",
    "               'days_active', 'avg_discount', 'gender_encoded', 'segment_encoded']\n",
    "\n",
    "# Prepare CLV data\n",
    "X_clv = active_customers[clv_features].fillna(0)\n",
    "y_clv = active_customers['total_spent']\n",
    "\n",
    "# Split data\n",
    "X_train_clv, X_test_clv, y_train_clv, y_test_clv = train_test_split(X_clv, y_clv, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler_clv = StandardScaler()\n",
    "X_train_clv_scaled = scaler_clv.fit_transform(X_train_clv)\n",
    "X_test_clv_scaled = scaler_clv.transform(X_test_clv)\n",
    "\n",
    "print(f\"ðŸ“Š CLV Training Set: {len(X_train_clv)} customers\")\n",
    "\n",
    "# Train CLV models\n",
    "print(\"\\nðŸ¤– Training CLV Prediction Models...\")\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_clv = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_clv.fit(X_train_clv, y_train_clv)\n",
    "\n",
    "# Linear Regression\n",
    "lr_clv = LinearRegression()\n",
    "lr_clv.fit(X_train_clv_scaled, y_train_clv)\n",
    "\n",
    "# Predictions\n",
    "rf_clv_pred = rf_clv.predict(X_test_clv)\n",
    "lr_clv_pred = lr_clv.predict(X_test_clv_scaled)\n",
    "\n",
    "# Evaluate CLV models\n",
    "rf_r2 = r2_score(y_test_clv, rf_clv_pred)\n",
    "lr_r2 = r2_score(y_test_clv, lr_clv_pred)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test_clv, rf_clv_pred))\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test_clv, lr_clv_pred))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ CLV Prediction Results:\")\n",
    "print(f\"Random Forest RÂ² Score: {rf_r2:.3f}, RMSE: ${rf_rmse:.2f}\")\n",
    "print(f\"Linear Regression RÂ² Score: {lr_r2:.3f}, RMSE: ${lr_rmse:.2f}\")\n",
    "\n",
    "# Predict future CLV for all active customers\n",
    "active_customers['predicted_clv'] = rf_clv.predict(X_clv)\n",
    "active_customers['clv_segment'] = pd.qcut(active_customers['predicted_clv'], \n",
    "                                         q=4, labels=['Low', 'Medium', 'High', 'Premium'])\n",
    "\n",
    "print(f\"\\nðŸ’Ž CLV Segmentation:\")\n",
    "clv_segments = active_customers.groupby('clv_segment').agg({\n",
    "    'customer_id': 'count',\n",
    "    'predicted_clv': 'mean',\n",
    "    'total_spent': 'mean'\n",
    "}).round(2)\n",
    "clv_segments.columns = ['Customer Count', 'Predicted CLV', 'Current Spent']\n",
    "print(clv_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701de92",
   "metadata": {},
   "source": [
    "### 4. SALES FORECASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3c98e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸ“ˆ STEP 4: Sales Forecasting\n",
      "------------------------------\n",
      "ðŸ“Š Sales Forecasting Data: 1066 days\n",
      "ðŸ“Š Forecast Training: 1036 days\n",
      "ðŸ“Š Forecast Testing: 30 days\n",
      "\n",
      "ðŸ¤– Training Sales Forecasting Model...\n",
      "\n",
      "ðŸ“ˆ Sales Forecasting Results:\n",
      "RÂ² Score: -0.190\n",
      "RMSE: $420.95\n",
      "Mean Actual Daily Revenue: $2107.45\n",
      "Mean Predicted Daily Revenue: $2122.92\n",
      "\n",
      "ðŸ”® Next 7 Days Revenue Forecast:\n",
      "   2024-12-31: $2,039.53\n",
      "   2025-01-01: $2,177.60\n",
      "   2025-01-02: $2,188.39\n",
      "   2025-01-03: $2,224.05\n",
      "   2025-01-04: $2,285.61\n",
      "   2025-01-05: $2,316.92\n",
      "   2025-01-06: $2,204.26\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nðŸ“ˆ STEP 4: Sales Forecasting\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Prepare time series data\n",
    "daily_sales = transactions.groupby('transaction_date').agg({\n",
    "    'total_amount': 'sum',\n",
    "    'transaction_id': 'count',\n",
    "    'customer_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "daily_sales.columns = ['daily_revenue', 'daily_orders', 'daily_customers']\n",
    "\n",
    "# Create date features\n",
    "daily_sales['day_of_week'] = daily_sales.index.dayofweek\n",
    "daily_sales['month'] = daily_sales.index.month\n",
    "daily_sales['quarter'] = daily_sales.index.quarter\n",
    "daily_sales['day_of_year'] = daily_sales.index.dayofyear\n",
    "\n",
    "# Create lag features\n",
    "daily_sales['revenue_lag_1'] = daily_sales['daily_revenue'].shift(1)\n",
    "daily_sales['revenue_lag_7'] = daily_sales['daily_revenue'].shift(7)\n",
    "daily_sales['revenue_ma_7'] = daily_sales['daily_revenue'].rolling(window=7).mean()\n",
    "daily_sales['revenue_ma_30'] = daily_sales['daily_revenue'].rolling(window=30).mean()\n",
    "\n",
    "# Remove rows with NaN values\n",
    "daily_sales_clean = daily_sales.dropna()\n",
    "\n",
    "print(f\"ðŸ“Š Sales Forecasting Data: {len(daily_sales_clean)} days\")\n",
    "\n",
    "# Features for forecasting\n",
    "forecast_features = ['day_of_week', 'month', 'quarter', 'day_of_year',\n",
    "                    'revenue_lag_1', 'revenue_lag_7', 'revenue_ma_7', 'revenue_ma_30']\n",
    "\n",
    "X_forecast = daily_sales_clean[forecast_features]\n",
    "y_forecast = daily_sales_clean['daily_revenue']\n",
    "\n",
    "# Split chronologically (last 30 days for testing)\n",
    "split_date = daily_sales_clean.index[-30]\n",
    "X_train_forecast = X_forecast[X_forecast.index < split_date]\n",
    "X_test_forecast = X_forecast[X_forecast.index >= split_date]\n",
    "y_train_forecast = y_forecast[y_forecast.index < split_date]\n",
    "y_test_forecast = y_forecast[y_forecast.index >= split_date]\n",
    "\n",
    "print(f\"ðŸ“Š Forecast Training: {len(X_train_forecast)} days\")\n",
    "print(f\"ðŸ“Š Forecast Testing: {len(X_test_forecast)} days\")\n",
    "\n",
    "# Train forecasting model\n",
    "print(\"\\nðŸ¤– Training Sales Forecasting Model...\")\n",
    "\n",
    "rf_forecast = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_forecast.fit(X_train_forecast, y_train_forecast)\n",
    "\n",
    "# Predict\n",
    "forecast_pred = rf_forecast.predict(X_test_forecast)\n",
    "\n",
    "# Evaluate forecasting\n",
    "forecast_r2 = r2_score(y_test_forecast, forecast_pred)\n",
    "forecast_rmse = np.sqrt(mean_squared_error(y_test_forecast, forecast_pred))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Sales Forecasting Results:\")\n",
    "print(f\"RÂ² Score: {forecast_r2:.3f}\")\n",
    "print(f\"RMSE: ${forecast_rmse:.2f}\")\n",
    "print(f\"Mean Actual Daily Revenue: ${y_test_forecast.mean():.2f}\")\n",
    "print(f\"Mean Predicted Daily Revenue: ${forecast_pred.mean():.2f}\")\n",
    "\n",
    "# Future forecasting (next 7 days)\n",
    "last_known_data = daily_sales_clean.iloc[-1:].copy()\n",
    "future_predictions = []\n",
    "\n",
    "print(f\"\\nðŸ”® Next 7 Days Revenue Forecast:\")\n",
    "for i in range(7):\n",
    "    # Use last known values for prediction\n",
    "    future_date = last_known_data.index[0] + timedelta(days=i+1)\n",
    "    \n",
    "    # Create features for future day\n",
    "    future_features = {\n",
    "        'day_of_week': future_date.dayofweek,\n",
    "        'month': future_date.month,\n",
    "        'quarter': (future_date.month - 1) // 3 + 1,\n",
    "        'day_of_year': future_date.dayofyear,\n",
    "        'revenue_lag_1': last_known_data['daily_revenue'].iloc[0] if i == 0 else future_predictions[-1],\n",
    "        'revenue_lag_7': last_known_data['daily_revenue'].iloc[0],\n",
    "        'revenue_ma_7': last_known_data['revenue_ma_7'].iloc[0],\n",
    "        'revenue_ma_30': last_known_data['revenue_ma_30'].iloc[0]\n",
    "    }\n",
    "    \n",
    "    # Predict future revenue\n",
    "    future_X = pd.DataFrame([future_features])\n",
    "    predicted_revenue = rf_forecast.predict(future_X)[0]\n",
    "    future_predictions.append(predicted_revenue)\n",
    "    \n",
    "    print(f\"   {future_date.strftime('%Y-%m-%d')}: ${predicted_revenue:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcdbd73",
   "metadata": {},
   "source": [
    "### 5. PRODUCT DEMAND FORECASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48753a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸ“¦ STEP 5: Product Demand Forecasting\n",
      "----------------------------------------\n",
      "ðŸ“Š Forecasting demand for top 20 products by volume\n",
      "\n",
      "ðŸ“Š Product Demand Analysis:\n",
      "   product_id                                      product_name  \\\n",
      "0         173  Triple-buffered logistical functionalities Crime   \n",
      "1         665               Implemented background matrices Way   \n",
      "2         331               Customer-focused secondary core Man   \n",
      "3         600          Persistent mobile Internet solution Meet   \n",
      "4         889            Public-key tangible data-warehouse Cup   \n",
      "\n",
      "        category  avg_daily_demand  demand_std  total_demand  \n",
      "0    Electronics              1.87        1.24           129  \n",
      "1           Toys              2.25        1.29           128  \n",
      "2  Home & Garden              1.85        1.11           126  \n",
      "3         Beauty              1.61        0.99           122  \n",
      "4  Home & Garden              1.69        0.98           120  \n",
      "\n",
      "ðŸ·ï¸ Category Demand Patterns:\n",
      "               avg_daily_demand  demand_std  total_demand\n",
      "category                                                 \n",
      "Toys                       1.97        1.17           590\n",
      "Home & Garden              1.68        0.98           470\n",
      "Electronics                1.84        1.12           358\n",
      "Beauty                     1.68        0.97           350\n",
      "Books                      1.76        1.06           232\n",
      "Clothing                   1.80        0.98           224\n",
      "Sports                     1.87        1.19           112\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nðŸ“¦ STEP 5: Product Demand Forecasting\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Analyze top products for demand forecasting\n",
    "top_products = transactions.groupby('product_id')['quantity'].sum().nlargest(20)\n",
    "print(f\"ðŸ“Š Forecasting demand for top 20 products by volume\")\n",
    "\n",
    "# Product demand features\n",
    "product_demand_data = []\n",
    "\n",
    "for product_id in top_products.index:\n",
    "    product_transactions = transactions[transactions['product_id'] == product_id].copy()\n",
    "    product_transactions = product_transactions.set_index('transaction_date')\n",
    "    \n",
    "    # Daily demand\n",
    "    daily_demand = product_transactions.groupby('transaction_date')['quantity'].sum()\n",
    "    \n",
    "    if len(daily_demand) > 30:  # Only products with sufficient history\n",
    "        # Create features\n",
    "        demand_df = daily_demand.to_frame('demand')\n",
    "        demand_df['day_of_week'] = demand_df.index.dayofweek\n",
    "        demand_df['month'] = demand_df.index.month\n",
    "        demand_df['demand_lag_1'] = demand_df['demand'].shift(1)\n",
    "        demand_df['demand_ma_7'] = demand_df['demand'].rolling(window=7).mean()\n",
    "        \n",
    "        # Get product info\n",
    "        product_info = products[products['product_id'] == product_id].iloc[0]\n",
    "        demand_df['price'] = product_info['price']\n",
    "        demand_df['category'] = product_info['category']\n",
    "        \n",
    "        product_demand_data.append({\n",
    "            'product_id': product_id,\n",
    "            'product_name': product_info['product_name'],\n",
    "            'category': product_info['category'],\n",
    "            'avg_daily_demand': daily_demand.mean(),\n",
    "            'demand_std': daily_demand.std(),\n",
    "            'total_demand': daily_demand.sum()\n",
    "        })\n",
    "\n",
    "demand_forecast_df = pd.DataFrame(product_demand_data)\n",
    "print(f\"\\nðŸ“Š Product Demand Analysis:\")\n",
    "print(demand_forecast_df.head().round(2))\n",
    "\n",
    "# Category demand patterns\n",
    "category_demand = demand_forecast_df.groupby('category').agg({\n",
    "    'avg_daily_demand': 'mean',\n",
    "    'demand_std': 'mean',\n",
    "    'total_demand': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nðŸ·ï¸ Category Demand Patterns:\")\n",
    "print(category_demand.sort_values('total_demand', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9e80b",
   "metadata": {},
   "source": [
    "### 6. CUSTOMER ACQUISITION PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c09648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸ‘¥ STEP 6: Customer Acquisition Forecasting\n",
      "---------------------------------------------\n",
      "ðŸ“Š Monthly Customer Acquisition Trend:\n",
      "reg_date\n",
      "2024-09    153\n",
      "2024-10    140\n",
      "2024-11    115\n",
      "2024-12    128\n",
      "2025-01    150\n",
      "2025-02    122\n",
      "2025-03    170\n",
      "2025-04    142\n",
      "2025-05    141\n",
      "2025-06    137\n",
      "2025-07    139\n",
      "2025-08     70\n",
      "Freq: M, dtype: int64\n",
      "\n",
      "ðŸ“ˆ Recent Acquisition Trend: -13.6% monthly change\n",
      "\n",
      "ðŸ”® Next 3 Months Acquisition Forecast:\n",
      "   Month +1: 99 new customers\n",
      "   Month +2: 86 new customers\n",
      "   Month +3: 74 new customers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\\nðŸ‘¥ STEP 6: Customer Acquisition Forecasting\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Analyze customer acquisition patterns\n",
    "customers['reg_date'] = pd.to_datetime(customers['registration_date'])\n",
    "monthly_acquisitions = customers.groupby(customers['reg_date'].dt.to_period('M')).size()\n",
    "\n",
    "print(f\"ðŸ“Š Monthly Customer Acquisition Trend:\")\n",
    "print(monthly_acquisitions.tail(12))\n",
    "\n",
    "# Simple trend analysis\n",
    "recent_months = monthly_acquisitions.tail(6)\n",
    "acquisition_trend = recent_months.pct_change().mean()\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Recent Acquisition Trend: {acquisition_trend*100:+.1f}% monthly change\")\n",
    "\n",
    "# Predict next 3 months acquisition\n",
    "last_3_avg = recent_months.tail(3).mean()\n",
    "predicted_acquisitions = []\n",
    "\n",
    "for i in range(3):\n",
    "    predicted = last_3_avg * (1 + acquisition_trend) ** (i + 1)\n",
    "    predicted_acquisitions.append(int(predicted))\n",
    "\n",
    "print(f\"\\nðŸ”® Next 3 Months Acquisition Forecast:\")\n",
    "for i, pred in enumerate(predicted_acquisitions, 1):\n",
    "    print(f\"   Month +{i}: {pred} new customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae614f9",
   "metadata": {},
   "source": [
    "### 7. RISK SCORING & SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571181de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "âš ï¸  STEP 7: Customer Risk Scoring & Segmentation\n",
      "--------------------------------------------------\n",
      "âš ï¸  Customer Risk Segmentation:\n",
      "             customer_id total_spent          churn_probability is_churned\n",
      "                   count         sum     mean              mean       mean\n",
      "risk_segment                                                              \n",
      "Low Risk             408   347002.18  850.496             0.248      0.064\n",
      "Medium Risk         4577  1927150.91  421.051             0.300      0.316\n",
      "High Risk             15     3110.49  207.366             0.602      0.867\n",
      "\n",
      "ðŸš¨ High-Value At-Risk Customers:\n",
      "   Count: 0\n",
      "   Total Value: $0.00\n",
      "   Avg Churn Probability: nan%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nâš ï¸  STEP 7: Customer Risk Scoring & Segmentation\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create comprehensive risk score\n",
    "customers_ml['risk_score'] = (\n",
    "    customers_ml['churn_probability'] * 0.4 +  # Churn risk\n",
    "    (customers_ml['days_since_last'] / customers_ml['days_since_last'].max()) * 0.3 +  # Recency risk\n",
    "    (1 - customers_ml['total_spent'] / customers_ml['total_spent'].max()) * 0.2 +  # Value risk\n",
    "    (customers_ml['support_tickets'] / customers_ml['support_tickets'].max()) * 0.1  # Support risk\n",
    ")\n",
    "\n",
    "# Risk segments\n",
    "customers_ml['risk_segment'] = pd.cut(customers_ml['risk_score'], \n",
    "                                     bins=[0, 0.3, 0.6, 1.0], \n",
    "                                     labels=['Low Risk', 'Medium Risk', 'High Risk'])\n",
    "\n",
    "risk_analysis = customers_ml.groupby('risk_segment').agg({\n",
    "    'customer_id': 'count',\n",
    "    'total_spent': ['sum', 'mean'],\n",
    "    'churn_probability': 'mean',\n",
    "    'is_churned': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(f\"âš ï¸  Customer Risk Segmentation:\")\n",
    "print(risk_analysis)\n",
    "\n",
    "# High-value at-risk customers\n",
    "high_value_at_risk = customers_ml[\n",
    "    (customers_ml['risk_segment'] == 'High Risk') & \n",
    "    (customers_ml['total_spent'] > customers_ml['total_spent'].quantile(0.75))\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸš¨ High-Value At-Risk Customers:\")\n",
    "print(f\"   Count: {len(high_value_at_risk)}\")\n",
    "print(f\"   Total Value: ${high_value_at_risk['total_spent'].sum():,.2f}\")\n",
    "print(f\"   Avg Churn Probability: {high_value_at_risk['churn_probability'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cb974",
   "metadata": {},
   "source": [
    "### 8. MODEL PERFORMANCE SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6cd288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸ“Š MODEL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "                    Model    Metric  Score    Status\n",
      "0   Churn Prediction (RF)  Accuracy  0.702  âš ï¸  Fair\n",
      "1   Churn Prediction (LR)  Accuracy  0.703  âš ï¸  Fair\n",
      "2     CLV Prediction (RF)        RÂ²  0.986    âœ… Good\n",
      "3     CLV Prediction (LR)        RÂ²  0.930    âœ… Good\n",
      "4  Sales Forecasting (RF)        RÂ² -0.190  âš ï¸  Fair\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\\nðŸ“Š MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model_performance = pd.DataFrame({\n",
    "    'Model': ['Churn Prediction (RF)', 'Churn Prediction (LR)', \n",
    "              'CLV Prediction (RF)', 'CLV Prediction (LR)',\n",
    "              'Sales Forecasting (RF)'],\n",
    "    'Metric': ['Accuracy', 'Accuracy', 'RÂ²', 'RÂ²', 'RÂ²'],\n",
    "    'Score': [accuracy_score(y_test, rf_pred), \n",
    "              accuracy_score(y_test, lr_pred),\n",
    "              rf_r2, lr_r2, forecast_r2],\n",
    "    'Status': ['âœ… Good' if accuracy_score(y_test, rf_pred) > 0.8 else 'âš ï¸  Fair',\n",
    "               'âœ… Good' if accuracy_score(y_test, lr_pred) > 0.8 else 'âš ï¸  Fair',\n",
    "               'âœ… Good' if rf_r2 > 0.7 else 'âš ï¸  Fair',\n",
    "               'âœ… Good' if lr_r2 > 0.7 else 'âš ï¸  Fair',\n",
    "               'âœ… Good' if forecast_r2 > 0.7 else 'âš ï¸  Fair']\n",
    "})\n",
    "\n",
    "print(model_performance.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a53478",
   "metadata": {},
   "source": [
    "### 9. BUSINESS IMPACT PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78869f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸ’¼ BUSINESS IMPACT PREDICTIONS\n",
      "========================================\n",
      "ðŸ’° Financial Impact Predictions:\n",
      "   Revenue at Risk (High Churn Probability): $5,126.54\n",
      "   Estimated Monthly Loss: $512.65\n",
      "\n",
      "ðŸ“ˆ Customer Lifetime Value Insights:\n",
      "   Current Total Customer Value: $1,605,801.97\n",
      "   Predicted Total CLV: $1,603,370.27\n",
      "   Growth Potential: $-2,431.70\n",
      "\n",
      "ðŸ“Š Short-term Revenue Forecast:\n",
      "   Next 7 Days Predicted Revenue: $15,436.36\n",
      "   Daily Average: $2,205.19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\\nðŸ’¼ BUSINESS IMPACT PREDICTIONS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Revenue at risk from churn\n",
    "revenue_at_risk = high_risk_customers['total_spent'].sum()\n",
    "monthly_revenue_loss = revenue_at_risk * 0.1  # Assume 10% monthly churn\n",
    "\n",
    "print(f\"ðŸ’° Financial Impact Predictions:\")\n",
    "print(f\"   Revenue at Risk (High Churn Probability): ${revenue_at_risk:,.2f}\")\n",
    "print(f\"   Estimated Monthly Loss: ${monthly_revenue_loss:,.2f}\")\n",
    "\n",
    "# CLV predictions\n",
    "total_predicted_clv = active_customers['predicted_clv'].sum()\n",
    "current_total_spent = active_customers['total_spent'].sum()\n",
    "clv_growth_potential = total_predicted_clv - current_total_spent\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Customer Lifetime Value Insights:\")\n",
    "print(f\"   Current Total Customer Value: ${current_total_spent:,.2f}\")\n",
    "print(f\"   Predicted Total CLV: ${total_predicted_clv:,.2f}\")\n",
    "print(f\"   Growth Potential: ${clv_growth_potential:,.2f}\")\n",
    "\n",
    "# Sales forecasting impact\n",
    "weekly_forecast = sum(future_predictions)\n",
    "print(f\"\\nðŸ“Š Short-term Revenue Forecast:\")\n",
    "print(f\"   Next 7 Days Predicted Revenue: ${weekly_forecast:,.2f}\")\n",
    "print(f\"   Daily Average: ${weekly_forecast/7:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f5480",
   "metadata": {},
   "source": [
    "### 10. ACTIONABLE INSIGHTS & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60191e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ðŸ’¡ PREDICTIVE INSIGHTS & RECOMMENDATIONS\n",
      "==================================================\n",
      "ðŸ”® WHAT WILL HAPPEN - KEY PREDICTIONS:\n",
      "\n",
      "ðŸŽ¯ Customer Churn:\n",
      "   â€¢ 9 customers likely to churn (>70% probability)\n",
      "   â€¢ $5,126.54 in revenue at risk\n",
      "   â€¢ Primary churn drivers: purchase_frequency, avg_order_value, total_spent\n",
      "\n",
      "ðŸ’° Customer Value:\n",
      "   â€¢ Premium CLV segment: 878 customers\n",
      "   â€¢ Growth potential: $-2,431.70\n",
      "\n",
      "ðŸ“ˆ Sales Forecast:\n",
      "   â€¢ Next week revenue: $15,436.36\n",
      "   â€¢ Model confidence: -19.0%\n",
      "\n",
      "ðŸ“¦ Product Demand:\n",
      "   â€¢ Top category by demand: Beauty\n",
      "   â€¢ Demand variability highest in: Toys\n",
      "\n",
      "ðŸŽ¯ IMMEDIATE ACTIONS RECOMMENDED:\n",
      "   âœ… Launch retention campaign for high-risk customers\n",
      "   âœ… Focus on Premium CLV segment for upselling\n",
      "   âœ… Optimize inventory for forecasted demand\n",
      "   âœ… Implement early warning system for churn indicators\n",
      "\n",
      "âš¡ NEXT: Prescriptive Analytics - What Should We Do?\n",
      "==================================================\n",
      "\n",
      "âœ… Predictive analysis complete! Predictions saved for prescriptive recommendations.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nðŸ’¡ PREDICTIVE INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"ðŸ”® WHAT WILL HAPPEN - KEY PREDICTIONS:\")\n",
    "print(f\"\\nðŸŽ¯ Customer Churn:\")\n",
    "print(f\"   â€¢ {len(high_risk_customers)} customers likely to churn (>70% probability)\")\n",
    "print(f\"   â€¢ ${revenue_at_risk:,.2f} in revenue at risk\")\n",
    "print(f\"   â€¢ Primary churn drivers: {', '.join(feature_importance.head(3)['feature'].tolist())}\")\n",
    "\n",
    "print(f\"\\nðŸ’° Customer Value:\")\n",
    "print(f\"   â€¢ Premium CLV segment: {len(active_customers[active_customers['clv_segment'] == 'Premium'])} customers\")\n",
    "print(f\"   â€¢ Growth potential: ${clv_growth_potential:,.2f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Sales Forecast:\")\n",
    "print(f\"   â€¢ Next week revenue: ${weekly_forecast:,.2f}\")\n",
    "print(f\"   â€¢ Model confidence: {forecast_r2:.1%}\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Product Demand:\")\n",
    "print(f\"   â€¢ Top category by demand: {category_demand.index[0]}\")\n",
    "print(f\"   â€¢ Demand variability highest in: {demand_forecast_df.nlargest(1, 'demand_std')['category'].iloc[0]}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ IMMEDIATE ACTIONS RECOMMENDED:\")\n",
    "print(\"   âœ… Launch retention campaign for high-risk customers\")\n",
    "print(\"   âœ… Focus on Premium CLV segment for upselling\")\n",
    "print(\"   âœ… Optimize inventory for forecasted demand\")\n",
    "print(\"   âœ… Implement early warning system for churn indicators\")\n",
    "\n",
    "print(f\"\\nâš¡ NEXT: Prescriptive Analytics - What Should We Do?\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Add predicted CLV to main dataframe for all customers\n",
    "customers_ml['predicted_clv'] = 0.0  # Default for churned customers\n",
    "customers_ml.loc[customers_ml['is_churned'] == 0, 'predicted_clv'] = active_customers['predicted_clv'].values\n",
    "\n",
    "# Save predictions for prescriptive analysis\n",
    "predictions_summary = {\n",
    "    'high_risk_customers': len(high_risk_customers),\n",
    "    'revenue_at_risk': float(revenue_at_risk),\n",
    "    'weekly_forecast': float(weekly_forecast),\n",
    "    'clv_growth_potential': float(clv_growth_potential),\n",
    "    'top_churn_features': feature_importance.head(5)['feature'].tolist(),\n",
    "    'analysis_date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('predictions_summary.json', 'w') as f:\n",
    "    json.dump(predictions_summary, f, default=str)\n",
    "\n",
    "# Save customer predictions\n",
    "customers_ml[['customer_id', 'churn_probability', 'predicted_clv', 'risk_segment']].to_csv('customer_predictions.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… Predictive analysis complete! Predictions saved for prescriptive recommendations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
