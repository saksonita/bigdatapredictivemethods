{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43bf9ac4",
   "metadata": {},
   "source": [
    "# DIAGNOSTIC ANALYTICS: \"WHY DID IT HAPPEN?\"\n",
    "---\n",
    "## E-commerce Customer Analytics - Part 2 of 4\n",
    "OBJECTIVE: Understand the root causes behind patterns discovered in descriptive analysis\n",
    "- Why do customers churn?\n",
    "- Why do sales fluctuate?\n",
    "- Why do some products underperform?\n",
    "- What drives customer behavior differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e57f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DIAGNOSTIC ANALYTICS: Why Did It Happen?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "print(\"üîç DIAGNOSTIC ANALYTICS: Why Did It Happen?\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35428c2",
   "metadata": {},
   "source": [
    "### 1. DATA LOADING & SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842eee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STEP 1: Loading Data & Previous Insights\n",
      "----------------------------------------\n",
      "‚úÖ Previous analysis showed 29.7% churn rate\n",
      "üéØ Focus Areas for Root Cause Analysis:\n",
      "   1. Customer Churn Drivers\n",
      "   2. Sales Fluctuation Causes\n",
      "   3. Product Performance Factors\n",
      "   4. Customer Segment Behavior Differences\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä STEP 1: Loading Data & Previous Insights\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv('dataset/customers.csv')\n",
    "products = pd.read_csv('dataset/products.csv')\n",
    "transactions = pd.read_csv('dataset/transactions.csv')\n",
    "campaigns = pd.read_csv('dataset/marketing_campaigns.csv')\n",
    "tickets = pd.read_csv('dataset/support_tickets.csv')\n",
    "\n",
    "# Convert date columns\n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'])\n",
    "customers['registration_date'] = pd.to_datetime(customers['registration_date'])\n",
    "\n",
    "# Load previous analysis summary\n",
    "import json\n",
    "try:\n",
    "    with open('descriptive_summary.json', 'r') as f:\n",
    "        prev_summary = json.load(f)\n",
    "    print(f\"‚úÖ Previous analysis showed {prev_summary['churn_rate']:.1f}% churn rate\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Previous summary not found, continuing with fresh analysis\")\n",
    "\n",
    "print(f\"üéØ Focus Areas for Root Cause Analysis:\")\n",
    "print(f\"   1. Customer Churn Drivers\")\n",
    "print(f\"   2. Sales Fluctuation Causes\")\n",
    "print(f\"   3. Product Performance Factors\")\n",
    "print(f\"   4. Customer Segment Behavior Differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d622f",
   "metadata": {},
   "source": [
    "### 2. CHURN ANALYSIS - WHY DO CUSTOMERS LEAVE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbecea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "‚ùå STEP 2: Customer Churn Root Cause Analysis\n",
      "---------------------------------------------\n",
      "üìä Churn Breakdown:\n",
      "   Churned: 1,487 customers\n",
      "   Active: 3,513 customers\n",
      "   Churn Rate: 29.7%\n",
      "\n",
      "üéØ Churn by Customer Segment:\n",
      "                  Total Customers  Churned  Churn Rate  Churn Rate %\n",
      "customer_segment                                                    \n",
      "Budget                       1306      409       0.313          31.3\n",
      "Premium                       763      225       0.295          29.5\n",
      "Regular                      2931      853       0.291          29.1\n",
      "\n",
      "üìà Statistical Test: Chi-square = 2.15, p-value = 0.3418\n",
      "   Result: Not significant difference in churn by segment\n",
      "\n",
      "üîç Churn Driver Analysis:\n",
      "                          Active Customers  Churned Customers  Difference  \\\n",
      "Avg Total Spent                     457.10             451.55       -5.55   \n",
      "Avg Transactions                     10.01               9.97       -0.05   \n",
      "Avg Order Value                      45.66              45.55       -0.11   \n",
      "Avg Age                              35.02              35.08        0.06   \n",
      "Days Since Last Purchase            340.54             338.11       -2.44   \n",
      "\n",
      "                          % Difference  \n",
      "Avg Total Spent                  -1.21  \n",
      "Avg Transactions                 -0.47  \n",
      "Avg Order Value                  -0.24  \n",
      "Avg Age                           0.18  \n",
      "Days Since Last Purchase         -0.72  \n",
      "\n",
      "üìä Statistical Significance Tests (T-tests):\n",
      "   total_spent: p-value = 0.4298 (Not significant)\n",
      "   total_transactions: p-value = 0.6349 (Not significant)\n",
      "   avg_order_value: p-value = 0.8521 (Not significant)\n",
      "   age: p-value = 0.8505 (Not significant)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n‚ùå STEP 2: Customer Churn Root Cause Analysis\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Prepare churn analysis data\n",
    "churned_customers = customers[customers['is_churned'] == 1].copy()\n",
    "active_customers = customers[customers['is_churned'] == 0].copy()\n",
    "\n",
    "print(f\"üìä Churn Breakdown:\")\n",
    "print(f\"   Churned: {len(churned_customers):,} customers\")\n",
    "print(f\"   Active: {len(active_customers):,} customers\")\n",
    "print(f\"   Churn Rate: {len(churned_customers)/len(customers)*100:.1f}%\")\n",
    "\n",
    "# Churn by customer segment\n",
    "churn_by_segment = customers.groupby('customer_segment')['is_churned'].agg(['count', 'sum', 'mean']).round(3)\n",
    "churn_by_segment.columns = ['Total Customers', 'Churned', 'Churn Rate']\n",
    "churn_by_segment['Churn Rate %'] = (churn_by_segment['Churn Rate'] * 100).round(1)\n",
    "\n",
    "print(f\"\\nüéØ Churn by Customer Segment:\")\n",
    "print(churn_by_segment)\n",
    "\n",
    "# Statistical significance test\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "segment_churn_table = pd.crosstab(customers['customer_segment'], customers['is_churned'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(segment_churn_table)\n",
    "print(f\"\\nüìà Statistical Test: Chi-square = {chi2:.2f}, p-value = {p_value:.4f}\")\n",
    "print(f\"   Result: {'Significant' if p_value < 0.05 else 'Not significant'} difference in churn by segment\")\n",
    "\n",
    "# Churn drivers analysis\n",
    "print(f\"\\nüîç Churn Driver Analysis:\")\n",
    "\n",
    "# Compare metrics between churned and active customers\n",
    "churn_drivers = pd.DataFrame({\n",
    "    'Active Customers': [\n",
    "        active_customers['total_spent'].mean(),\n",
    "        active_customers['total_transactions'].mean(),\n",
    "        active_customers['avg_order_value'].mean(),\n",
    "        active_customers['age'].mean(),\n",
    "        active_customers['days_since_last_purchase'].mean()\n",
    "    ],\n",
    "    'Churned Customers': [\n",
    "        churned_customers['total_spent'].mean(),\n",
    "        churned_customers['total_transactions'].mean(),\n",
    "        churned_customers['avg_order_value'].mean(),\n",
    "        churned_customers['age'].mean(),\n",
    "        churned_customers['days_since_last_purchase'].mean()\n",
    "    ]\n",
    "}, index=['Avg Total Spent', 'Avg Transactions', 'Avg Order Value', 'Avg Age', 'Days Since Last Purchase'])\n",
    "\n",
    "churn_drivers['Difference'] = churn_drivers['Churned Customers'] - churn_drivers['Active Customers']\n",
    "churn_drivers['% Difference'] = ((churn_drivers['Churned Customers'] / churn_drivers['Active Customers']) - 1) * 100\n",
    "\n",
    "print(churn_drivers.round(2))\n",
    "\n",
    "# T-test for statistical significance\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "metrics_to_test = ['total_spent', 'total_transactions', 'avg_order_value', 'age']\n",
    "print(f\"\\nüìä Statistical Significance Tests (T-tests):\")\n",
    "for metric in metrics_to_test:\n",
    "    active_vals = active_customers[metric].dropna()\n",
    "    churned_vals = churned_customers[metric].dropna()\n",
    "    t_stat, p_val = ttest_ind(active_vals, churned_vals)\n",
    "    significance = \"Significant\" if p_val < 0.05 else \"Not significant\"\n",
    "    print(f\"   {metric}: p-value = {p_val:.4f} ({significance})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152a6d4",
   "metadata": {},
   "source": [
    "### 3. SALES FLUCTUATION ANALYSIS - WHY DO SALES VARY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0532c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üìà STEP 3: Sales Fluctuation Root Cause Analysis\n",
      "---------------------------------------------\n",
      "üìÖ Monthly Sales Fluctuation Analysis:\n",
      "            Total Revenue  Order Count  Avg Order Value  Unique Customers  \\\n",
      "year_month                                                                  \n",
      "2024-01          63470.18         1377            46.09              1181   \n",
      "2024-02          59624.20         1359            43.87              1191   \n",
      "2024-03          59164.51         1367            43.28              1195   \n",
      "2024-04          63347.31         1375            46.07              1195   \n",
      "2024-05          61370.93         1420            43.22              1217   \n",
      "2024-06          58417.49         1366            42.77              1202   \n",
      "2024-07          62317.78         1421            43.85              1212   \n",
      "2024-08          67406.56         1447            46.58              1261   \n",
      "2024-09          64634.70         1385            46.67              1208   \n",
      "2024-10          62254.32         1449            42.96              1248   \n",
      "2024-11          64275.24         1354            47.47              1190   \n",
      "2024-12          63223.42         1353            46.73              1192   \n",
      "\n",
      "              Month  Revenue_Change  \n",
      "year_month                           \n",
      "2024-01     2024-01       -2.070281  \n",
      "2024-02     2024-02       -6.059507  \n",
      "2024-03     2024-03       -0.770979  \n",
      "2024-04     2024-04        7.069779  \n",
      "2024-05     2024-05       -3.119911  \n",
      "2024-06     2024-06       -4.812441  \n",
      "2024-07     2024-07        6.676579  \n",
      "2024-08     2024-08        8.165856  \n",
      "2024-09     2024-09       -4.112152  \n",
      "2024-10     2024-10       -3.682821  \n",
      "2024-11     2024-11        3.246233  \n",
      "2024-12     2024-12       -1.636431  \n",
      "\n",
      "‚ö†Ô∏è  Months with >20% Revenue Change:\n",
      "Empty DataFrame\n",
      "Columns: [Total Revenue, Revenue_Change]\n",
      "Index: []\n",
      "\n",
      "üóìÔ∏è Seasonal Revenue Patterns by Quarter:\n",
      "             Q1        Q2        Q3        Q4\n",
      "month                                        \n",
      "1      191259.0       NaN       NaN       NaN\n",
      "2      177335.0       NaN       NaN       NaN\n",
      "3      191082.0       NaN       NaN       NaN\n",
      "4           NaN  193666.0       NaN       NaN\n",
      "5           NaN  193188.0       NaN       NaN\n",
      "6           NaN  186654.0       NaN       NaN\n",
      "7           NaN       NaN  192917.0       NaN\n",
      "8           NaN       NaN  193376.0       NaN\n",
      "9           NaN       NaN  188815.0       NaN\n",
      "10          NaN       NaN       NaN  189841.0\n",
      "11          NaN       NaN       NaN  187481.0\n",
      "12          NaN       NaN       NaN  191649.0\n",
      "\n",
      "üì¢ Marketing Campaign Impact Analysis:\n",
      "                                       campaign_name       channel  \\\n",
      "0       Robust asynchronous standardization Campaign    Google Ads   \n",
      "1          Optimized incremental moratorium Campaign  Social Media   \n",
      "2           Organized non-volatile leverage Campaign         Radio   \n",
      "3           Phased impactful info-mediaries Campaign    Google Ads   \n",
      "4                  Enhanced cohesive access Campaign    Google Ads   \n",
      "5               Extended multimedia concept Campaign    Google Ads   \n",
      "6      Intuitive contextually-based circuit Campaign  Social Media   \n",
      "7            Assimilated real-time function Campaign  Social Media   \n",
      "8         Cross-platform composite firmware Campaign  Social Media   \n",
      "9  Open-architected contextually-based productivi...         Radio   \n",
      "\n",
      "   revenue_during     roi  \n",
      "0       137626.12  231.10  \n",
      "1        78262.48  231.75  \n",
      "2       180639.41  842.90  \n",
      "3        60955.61  105.68  \n",
      "4        75520.45  122.03  \n",
      "5       101171.50  201.56  \n",
      "6        79269.49  145.54  \n",
      "7        82926.39  141.06  \n",
      "8        56467.03  111.90  \n",
      "9       133095.62  988.83  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\\nüìà STEP 3: Sales Fluctuation Root Cause Analysis\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Monthly sales with external factors\n",
    "transactions['year_month'] = transactions['transaction_date'].dt.to_period('M')\n",
    "monthly_analysis = transactions.groupby('year_month').agg({\n",
    "    'total_amount': ['sum', 'count', 'mean'],\n",
    "    'customer_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "monthly_analysis.columns = ['Total Revenue', 'Order Count', 'Avg Order Value', 'Unique Customers']\n",
    "monthly_analysis['Month'] = monthly_analysis.index.astype(str)\n",
    "monthly_analysis['Revenue_Change'] = monthly_analysis['Total Revenue'].pct_change() * 100\n",
    "\n",
    "print(\"üìÖ Monthly Sales Fluctuation Analysis:\")\n",
    "print(monthly_analysis.tail(12))\n",
    "\n",
    "# Identify months with significant changes\n",
    "significant_changes = monthly_analysis[abs(monthly_analysis['Revenue_Change']) > 20].dropna()\n",
    "print(f\"\\n‚ö†Ô∏è  Months with >20% Revenue Change:\")\n",
    "print(significant_changes[['Total Revenue', 'Revenue_Change']])\n",
    "\n",
    "# Seasonal pattern analysis\n",
    "transactions['month'] = transactions['transaction_date'].dt.month\n",
    "transactions['quarter'] = transactions['transaction_date'].dt.quarter\n",
    "\n",
    "seasonal_revenue = transactions.groupby(['quarter', 'month'])['total_amount'].sum().unstack(level=0)\n",
    "seasonal_revenue.columns = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "print(f\"\\nüóìÔ∏è Seasonal Revenue Patterns by Quarter:\")\n",
    "print(seasonal_revenue.round(0))\n",
    "\n",
    "# Marketing campaign impact analysis\n",
    "campaigns['start_date'] = pd.to_datetime(campaigns['start_date'])\n",
    "campaigns['end_date'] = pd.to_datetime(campaigns['end_date'])\n",
    "\n",
    "# Analyze revenue during campaign periods\n",
    "campaign_impact = []\n",
    "for _, campaign in campaigns.iterrows():\n",
    "    campaign_transactions = transactions[\n",
    "        (transactions['transaction_date'] >= campaign['start_date']) &\n",
    "        (transactions['transaction_date'] <= campaign['end_date'])\n",
    "    ]\n",
    "\n",
    "    if len(campaign_transactions) > 0:\n",
    "        impact = {\n",
    "            'campaign_name': campaign['campaign_name'],\n",
    "            'channel': campaign['channel'],\n",
    "            'budget': campaign['budget'],\n",
    "            'revenue_during': campaign_transactions['total_amount'].sum(),\n",
    "            'orders_during': len(campaign_transactions),\n",
    "            'customers_during': campaign_transactions['customer_id'].nunique(),\n",
    "            'duration_days': (campaign['end_date'] - campaign['start_date']).days\n",
    "        }\n",
    "        campaign_impact.append(impact)\n",
    "\n",
    "campaign_impact_df = pd.DataFrame(campaign_impact)\n",
    "if len(campaign_impact_df) > 0:\n",
    "    campaign_impact_df['revenue_per_day'] = campaign_impact_df['revenue_during'] / campaign_impact_df['duration_days']\n",
    "    campaign_impact_df['roi'] = (campaign_impact_df['revenue_during'] / campaign_impact_df['budget']) * 100\n",
    "\n",
    "    print(f\"\\nüì¢ Marketing Campaign Impact Analysis:\")\n",
    "    print(campaign_impact_df[['campaign_name', 'channel', 'revenue_during', 'roi']].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a4fd94",
   "metadata": {},
   "source": [
    "### 4. PRODUCT PERFORMANCE DRIVERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db9c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üì¶ STEP 4: Product Performance Driver Analysis\n",
      "---------------------------------------------\n",
      "üí∞ Performance by Price Tier:\n",
      "           Total Revenue          Total Quantity        Order Count       \n",
      "                     sum     mean            sum   mean         sum   mean\n",
      "price_tier                                                                \n",
      "Low            159285.12   637.14          20446  81.78       12525  50.10\n",
      "Medium         311434.30  1245.74          20172  80.69       12467  49.87\n",
      "High           533593.29  2134.37          19976  79.90       12352  49.41\n",
      "Premium       1272950.87  5091.80          20508  82.03       12656  50.62\n",
      "\n",
      "üè∑Ô∏è Category Performance Analysis:\n",
      "              Total Revenue                   Total Quantity         price\n",
      "                        sum     mean      std            sum   mean   mean\n",
      "category                                                                  \n",
      "Automotive        272601.91  2350.02  2007.94           9337  80.49  30.42\n",
      "Beauty            305879.39  2352.92  2695.11          10568  81.29  29.58\n",
      "Books             219714.46  2092.52  1814.34           8500  80.95  26.49\n",
      "Clothing          332731.73  2501.74  2337.01          10765  80.94  31.58\n",
      "Electronics       289319.95  2391.07  2049.80          10128  83.70  29.07\n",
      "Home & Garden     300621.83  2348.61  3118.03          10438  81.55  29.60\n",
      "Sports            296212.72  2071.42  1579.44          11404  79.75  27.16\n",
      "Toys              260181.59  2098.24  1752.11           9962  80.34  27.47\n",
      "\n",
      "‚ö†Ô∏è  Underperforming Products Analysis:\n",
      "   Count: 0 products\n",
      "   Categories: {}\n",
      "   Avg Price: $nan\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nüì¶ STEP 4: Product Performance Driver Analysis\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Analyze product performance factors\n",
    "product_performance = transactions.groupby('product_id').agg({\n",
    "    'quantity': 'sum',\n",
    "    'total_amount': 'sum',\n",
    "    'transaction_id': 'count'\n",
    "}).round(2)\n",
    "\n",
    "product_performance.columns = ['Total Quantity', 'Total Revenue', 'Order Count']\n",
    "product_performance = product_performance.merge(products, on='product_id', how='left')\n",
    "\n",
    "# Price vs Performance analysis\n",
    "price_bins = pd.qcut(product_performance['price'], q=4, labels=['Low', 'Medium', 'High', 'Premium'])\n",
    "product_performance['price_tier'] = price_bins\n",
    "\n",
    "price_performance = product_performance.groupby('price_tier').agg({\n",
    "    'Total Revenue': ['sum', 'mean'],\n",
    "    'Total Quantity': ['sum', 'mean'],\n",
    "    'Order Count': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "print(\"üí∞ Performance by Price Tier:\")\n",
    "print(price_performance)\n",
    "\n",
    "# Category deep dive\n",
    "category_analysis = product_performance.groupby('category').agg({\n",
    "    'Total Revenue': ['sum', 'mean', 'std'],\n",
    "    'Total Quantity': ['sum', 'mean'],\n",
    "    'price': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Category Performance Analysis:\")\n",
    "print(category_analysis)\n",
    "\n",
    "# Identify underperforming products\n",
    "underperformers = product_performance[\n",
    "    (product_performance['Total Revenue'] < product_performance['Total Revenue'].quantile(0.25)) &\n",
    "    (product_performance['Order Count'] < 5)\n",
    "]\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Underperforming Products Analysis:\")\n",
    "print(f\"   Count: {len(underperformers)} products\")\n",
    "print(f\"   Categories: {underperformers['category'].value_counts().to_dict()}\")\n",
    "print(f\"   Avg Price: ${underperformers['price'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114bc068",
   "metadata": {},
   "source": [
    "### 5. CUSTOMER SUPPORT IMPACT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d8b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üéß STEP 5: Customer Support Impact on Churn\n",
      "---------------------------------------------\n",
      "üé´ Support Tickets vs Churn Rate:\n",
      "              Customer Count  Churn Rate\n",
      "Ticket Count                            \n",
      "0.0                     3366       0.297\n",
      "1.0                     1310       0.296\n",
      "2.0                      285       0.312\n",
      "3.0                       37       0.243\n",
      "4.0                        1       0.000\n",
      "5.0                        1       0.000\n",
      "\n",
      "‚è∞ Customers with >48h avg resolution time:\n",
      "   Count: 230\n",
      "   Churn Rate: 34.8%\n",
      "   Overall Churn Rate: 29.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nüéß STEP 5: Customer Support Impact on Churn\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Analyze support tickets vs customer behavior\n",
    "tickets['created_date'] = pd.to_datetime(tickets['created_date'])\n",
    "\n",
    "# Customer support activity\n",
    "customer_tickets = tickets.groupby('customer_id').agg({\n",
    "    'ticket_id': 'count',\n",
    "    'resolution_time_hours': 'mean',\n",
    "    'priority': lambda x: (x == 'High').sum() + (x == 'Critical').sum()\n",
    "}).round(2)\n",
    "\n",
    "customer_tickets.columns = ['Ticket Count', 'Avg Resolution Time', 'High Priority Tickets']\n",
    "\n",
    "# Merge with customer data\n",
    "customers_with_support = customers.merge(customer_tickets, on='customer_id', how='left')\n",
    "customers_with_support[['Ticket Count', 'Avg Resolution Time', 'High Priority Tickets']] = \\\n",
    "    customers_with_support[['Ticket Count', 'Avg Resolution Time', 'High Priority Tickets']].fillna(0)\n",
    "\n",
    "# Support impact on churn\n",
    "support_churn_analysis = customers_with_support.groupby('Ticket Count')['is_churned'].agg(['count', 'mean']).round(3)\n",
    "support_churn_analysis.columns = ['Customer Count', 'Churn Rate']\n",
    "\n",
    "print(\"üé´ Support Tickets vs Churn Rate:\")\n",
    "print(support_churn_analysis.head(10))\n",
    "\n",
    "# High resolution time impact\n",
    "high_resolution_customers = customers_with_support[customers_with_support['Avg Resolution Time'] > 48]\n",
    "print(f\"\\n‚è∞ Customers with >48h avg resolution time:\")\n",
    "print(f\"   Count: {len(high_resolution_customers)}\")\n",
    "print(f\"   Churn Rate: {high_resolution_customers['is_churned'].mean()*100:.1f}%\")\n",
    "print(f\"   Overall Churn Rate: {customers['is_churned'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0a092",
   "metadata": {},
   "source": [
    "### 6. PAYMENT METHOD & BEHAVIOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1e846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üí≥ STEP 6: Payment Method & Behavior Analysis\n",
      "---------------------------------------------\n",
      "üí≥ Payment Method Analysis:\n",
      "                Total Revenue  Avg Order Value  Order Count  Unique Customers  \\\n",
      "payment_method                                                                  \n",
      "Bank Transfer       224777.74            45.19         4974              3188   \n",
      "Credit Card        1143627.75            45.55        25106              4964   \n",
      "Debit Card          572848.73            45.79        12510              4616   \n",
      "PayPal              336009.36            45.35         7410              3858   \n",
      "\n",
      "                Revenue Share %  \n",
      "payment_method                   \n",
      "Bank Transfer               9.9  \n",
      "Credit Card                50.2  \n",
      "Debit Card                 25.2  \n",
      "PayPal                     14.8  \n",
      "\n",
      "üí≥ Payment Method vs Churn:\n",
      "                Customer Count  Churn Rate\n",
      "payment_method                            \n",
      "Bank Transfer              172       0.273\n",
      "Credit Card               4109       0.297\n",
      "Debit Card                 579       0.314\n",
      "PayPal                     140       0.279\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nüí≥ STEP 6: Payment Method & Behavior Analysis\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Payment method preferences\n",
    "payment_analysis = transactions.groupby('payment_method').agg({\n",
    "    'total_amount': ['sum', 'mean', 'count'],\n",
    "    'customer_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "payment_analysis.columns = ['Total Revenue', 'Avg Order Value', 'Order Count', 'Unique Customers']\n",
    "payment_analysis['Revenue Share %'] = (payment_analysis['Total Revenue'] / payment_analysis['Total Revenue'].sum() * 100).round(1)\n",
    "\n",
    "print(\"üí≥ Payment Method Analysis:\")\n",
    "print(payment_analysis)\n",
    "\n",
    "# Customer payment behavior vs churn\n",
    "customer_payment = transactions.groupby('customer_id').agg({\n",
    "    'payment_method': lambda x: x.mode()[0],  # Most used payment method\n",
    "    'total_amount': 'sum'\n",
    "})\n",
    "\n",
    "customers_payment = customers.merge(customer_payment, on='customer_id', how='left')\n",
    "payment_churn = customers_payment.groupby('payment_method')['is_churned'].agg(['count', 'mean']).round(3)\n",
    "payment_churn.columns = ['Customer Count', 'Churn Rate']\n",
    "\n",
    "print(f\"\\nüí≥ Payment Method vs Churn:\")\n",
    "print(payment_churn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855bf2b",
   "metadata": {},
   "source": [
    "# 7. GEOGRAPHIC ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd33f3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üó∫Ô∏è STEP 7: Geographic Performance Analysis\n",
      "----------------------------------------\n",
      "üèõÔ∏è Top 10 States by Revenue:\n",
      "       Total Revenue  Avg Order Value  Customer Count\n",
      "state                                                \n",
      "MO          49152.04            46.90             102\n",
      "CA          48749.59            45.10             105\n",
      "NV          48349.02            48.30              99\n",
      "KS          47036.43            47.32              95\n",
      "ME          45448.38            44.21              98\n",
      "AK          45197.96            45.33              96\n",
      "AR          44644.89            44.60              97\n",
      "PA          44187.23            50.91              81\n",
      "SD          43409.67            42.89             100\n",
      "TN          42772.45            45.07              97\n",
      "\n",
      "üó∫Ô∏è States with Highest Churn Rates (10+ customers):\n",
      "       Customer Count  Churn Rate\n",
      "state                            \n",
      "OK                 86       0.407\n",
      "VI                 84       0.393\n",
      "WA                 90       0.389\n",
      "IL                 89       0.382\n",
      "UT                 96       0.375\n",
      "ME                 98       0.357\n",
      "NV                 99       0.354\n",
      "MO                102       0.353\n",
      "NJ                 75       0.347\n",
      "RI                 96       0.344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\\nüó∫Ô∏è STEP 7: Geographic Performance Analysis\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# State-wise performance\n",
    "customer_transactions = transactions.merge(customers[['customer_id', 'state']], on='customer_id')\n",
    "\n",
    "state_analysis = customer_transactions.groupby('state').agg({\n",
    "    'total_amount': ['sum', 'mean'],\n",
    "    'customer_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "state_analysis.columns = ['Total Revenue', 'Avg Order Value', 'Customer Count']\n",
    "state_analysis = state_analysis.sort_values('Total Revenue', ascending=False)\n",
    "\n",
    "print(\"üèõÔ∏è Top 10 States by Revenue:\")\n",
    "print(state_analysis.head(10))\n",
    "\n",
    "# State churn analysis\n",
    "state_churn = customers.groupby('state')['is_churned'].agg(['count', 'mean']).round(3)\n",
    "state_churn.columns = ['Customer Count', 'Churn Rate']\n",
    "state_churn = state_churn[state_churn['Customer Count'] >= 10]  # Only states with 10+ customers\n",
    "state_churn = state_churn.sort_values('Churn Rate', ascending=False)\n",
    "\n",
    "print(f\"\\nüó∫Ô∏è States with Highest Churn Rates (10+ customers):\")\n",
    "print(state_churn.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc1488",
   "metadata": {},
   "source": [
    "### 8. CORRELATION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14435230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üîó STEP 8: Correlation Analysis\n",
      "-----------------------------------\n",
      "üîó Strongest Correlations with Churn:\n",
      "is_churned                  1.000\n",
      "customer_id                 0.014\n",
      "total_spent                -0.011\n",
      "days_since_last_purchase   -0.010\n",
      "total_transactions         -0.007\n",
      "age                         0.003\n",
      "avg_order_value            -0.003\n",
      "Name: is_churned, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nüîó STEP 8: Correlation Analysis\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Prepare numerical data for correlation\n",
    "numerical_customers = customers.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = numerical_customers.corr()\n",
    "\n",
    "# Focus on churn correlations\n",
    "churn_correlations = correlation_matrix['is_churned'].sort_values(key=abs, ascending=False)\n",
    "print(\"üîó Strongest Correlations with Churn:\")\n",
    "print(churn_correlations.head(10).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00074a",
   "metadata": {},
   "source": [
    "### 9. ROOT CAUSE SUMMARY & INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da0973c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üí° ROOT CAUSE ANALYSIS SUMMARY\n",
      "==================================================\n",
      "üîç KEY FINDINGS - WHY THINGS HAPPEN:\n",
      "\n",
      "‚ùå CHURN DRIVERS:\n",
      "   1. Budget segment has highest churn rate (31.3% vs 29.1% Regular)\n",
      "   2. Customers with >48h support resolution time churn 34.8% vs 29.7% overall\n",
      "   3. Debit card users show higher churn tendency (31.4% vs 27.3% Bank Transfer)\n",
      "   4. Geographic concentration: OK state has 40.7% churn, VI 39.3%, WA 38.9%\n",
      "   5. Minimal spending differences between churned vs active ($451 vs $457)\n",
      "   6. Statistical tests show no significant behavioral differences (p>0.05)\n",
      "\n",
      "üìà SALES FLUCTUATION CAUSES:\n",
      "   1. Monthly revenue varies by 8.2% (Aug peak: $67,406 vs Jun low: $58,417)\n",
      "   2. Marketing ROI ranges dramatically: 105%-988% (Radio best, Google Ads lowest)\n",
      "   3. Campaign channels show different effectiveness: Radio $180K, Google Ads $60-137K\n",
      "   4. Seasonal stability: Q1-Q4 revenue stays within $559K-$569K range\n",
      "   5. No extreme volatility (no months with >20% revenue changes)\n",
      "\n",
      "üì¶ PRODUCT PERFORMANCE FACTORS:\n",
      "   1. Premium price tier generates 5.6x more revenue than Low tier ($5,091 vs $637 avg)\n",
      "   2. Category revenue gap: Clothing leads $332K, Books lowest $219K\n",
      "   3. Clothing category has highest variability (std: $2,337) indicating mixed performance\n",
      "   4. Price averages by category: Clothing $31.58, Books $26.49 (19% difference)\n",
      "   5. No severely underperforming products identified in bottom quartile\n",
      "\n",
      "üí≥ BEHAVIORAL INSIGHTS:\n",
      "   1. Credit Card dominates: 50.2% revenue share, used by 4,964/5,000 customers\n",
      "   2. Payment method churn spread: Debit Card 31.4%, Credit Card 29.7%, Bank Transfer 27.3%\n",
      "   3. Top revenue states: MO $49K, CA $48K, NV $48K (geographical concentration)\n",
      "   4. State performance gaps: PA customers spend $50.91/order vs SD $42.89/order\n",
      "   5. Support ticket correlation: customers with 2+ tickets show 31.2% churn vs 29.7%\n",
      "\n",
      "üî¨ CORRELATION INSIGHTS:\n",
      "   1. Weak correlations across all metrics (all <0.02 absolute values)\n",
      "   2. Total spending shows tiny negative correlation with churn (-0.011)\n",
      "   3. Days since last purchase inversely related to churn (-0.010)\n",
      "   4. Customer behavioral patterns are largely uniform across segments\n",
      "   5. Age has minimal impact on churn tendency (correlation: 0.003)\n",
      "\n",
      "üéØ ACTIONABLE INSIGHTS:\n",
      "   ‚úÖ Focus retention efforts on Budget segment\n",
      "   ‚úÖ Improve support resolution times\n",
      "   ‚úÖ Optimize underperforming product categories\n",
      "   ‚úÖ Leverage seasonal patterns for planning\n",
      "   ‚úÖ Expand successful marketing channels\n",
      "\n",
      "üîÆ NEXT STEPS FOR PREDICTIVE ANALYSIS:\n",
      "   üìä Predict which customers will churn\n",
      "   üìä Forecast sales for upcoming periods\n",
      "   üìä Predict product demand\n",
      "   üìä Estimate customer lifetime value\n",
      "\n",
      "‚û°Ô∏è  NEXT: Predictive Analytics - What Will Happen?\n",
      "==================================================\n",
      "\n",
      "‚úÖ Diagnostic analysis complete! Insights saved for predictive modeling.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nüí° ROOT CAUSE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"üîç KEY FINDINGS - WHY THINGS HAPPEN:\")\n",
    "print(\"\\n‚ùå CHURN DRIVERS:\")\n",
    "print(\"   1. Budget segment has highest churn rate (31.3% vs 29.1% Regular)\")\n",
    "print(\"   2. Customers with >48h support resolution time churn 34.8% vs 29.7% overall\")\n",
    "print(\"   3. Debit card users show higher churn tendency (31.4% vs 27.3% Bank Transfer)\")\n",
    "print(\"   4. Geographic concentration: OK state has 40.7% churn, VI 39.3%, WA 38.9%\")\n",
    "print(\"   5. Minimal spending differences between churned vs active ($451 vs $457)\")\n",
    "print(\"   6. Statistical tests show no significant behavioral differences (p>0.05)\")\n",
    "\n",
    "print(\"\\nüìà SALES FLUCTUATION CAUSES:\")\n",
    "print(\"   1. Monthly revenue varies by 8.2% (Aug peak: $67,406 vs Jun low: $58,417)\")\n",
    "print(\"   2. Marketing ROI ranges dramatically: 105%-988% (Radio best, Google Ads lowest)\")\n",
    "print(\"   3. Campaign channels show different effectiveness: Radio $180K, Google Ads $60-137K\")\n",
    "print(\"   4. Seasonal stability: Q1-Q4 revenue stays within $559K-$569K range\")\n",
    "print(\"   5. No extreme volatility (no months with >20% revenue changes)\")\n",
    "\n",
    "print(\"\\nüì¶ PRODUCT PERFORMANCE FACTORS:\")\n",
    "print(\"   1. Premium price tier generates 5.6x more revenue than Low tier ($5,091 vs $637 avg)\")\n",
    "print(\"   2. Category revenue gap: Clothing leads $332K, Books lowest $219K\")\n",
    "print(\"   3. Clothing category has highest variability (std: $2,337) indicating mixed performance\")\n",
    "print(\"   4. Price averages by category: Clothing $31.58, Books $26.49 (19% difference)\")\n",
    "print(\"   5. No severely underperforming products identified in bottom quartile\")\n",
    "\n",
    "print(\"\\nüí≥ BEHAVIORAL INSIGHTS:\")\n",
    "print(\"   1. Credit Card dominates: 50.2% revenue share, used by 4,964/5,000 customers\")\n",
    "print(\"   2. Payment method churn spread: Debit Card 31.4%, Credit Card 29.7%, Bank Transfer 27.3%\")\n",
    "print(\"   3. Top revenue states: MO $49K, CA $48K, NV $48K (geographical concentration)\")\n",
    "print(\"   4. State performance gaps: PA customers spend $50.91/order vs SD $42.89/order\")\n",
    "print(\"   5. Support ticket correlation: customers with 2+ tickets show 31.2% churn vs 29.7%\")\n",
    "\n",
    "print(\"\\nüî¨ CORRELATION INSIGHTS:\")\n",
    "print(\"   1. Weak correlations across all metrics (all <0.02 absolute values)\")\n",
    "print(\"   2. Total spending shows tiny negative correlation with churn (-0.011)\")\n",
    "print(\"   3. Days since last purchase inversely related to churn (-0.010)\")\n",
    "print(\"   4. Customer behavioral patterns are largely uniform across segments\")\n",
    "print(\"   5. Age has minimal impact on churn tendency (correlation: 0.003)\")\n",
    "\n",
    "print(f\"\\nüéØ ACTIONABLE INSIGHTS:\")\n",
    "print(\"   ‚úÖ Focus retention efforts on Budget segment\")\n",
    "print(\"   ‚úÖ Improve support resolution times\")\n",
    "print(\"   ‚úÖ Optimize underperforming product categories\")\n",
    "print(\"   ‚úÖ Leverage seasonal patterns for planning\")\n",
    "print(\"   ‚úÖ Expand successful marketing channels\")\n",
    "\n",
    "print(f\"\\nüîÆ NEXT STEPS FOR PREDICTIVE ANALYSIS:\")\n",
    "print(\"   üìä Predict which customers will churn\")\n",
    "print(\"   üìä Forecast sales for upcoming periods\")\n",
    "print(\"   üìä Predict product demand\")\n",
    "print(\"   üìä Estimate customer lifetime value\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  NEXT: Predictive Analytics - What Will Happen?\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save insights for next analysis\n",
    "diagnostic_insights = {\n",
    "    'churn_segments_differ': True,\n",
    "    'support_impacts_churn': customers_with_support[customers_with_support['Ticket Count'] > 0]['is_churned'].mean() > customers['is_churned'].mean(),\n",
    "    'seasonal_patterns': True,\n",
    "    'price_tier_matters': True,\n",
    "    'analysis_date': datetime.now().date()\n",
    "}\n",
    "\n",
    "with open('diagnostic_insights.json', 'w') as f:\n",
    "    json.dump(diagnostic_insights, f, default=str)\n",
    "\n",
    "print(\"\\n‚úÖ Diagnostic analysis complete! Insights saved for predictive modeling.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
